{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(host = 'localhost', port = 6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_info = client.get_collection(collection_name = 'course_83c94b40-9dc0-4253-b83c-b82218156493')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=148 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=768, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfig(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, filter_max_conditions=None, condition_max_size=None)) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "print(collection_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = client.scroll(collection_name = 'course_83c94b40-9dc0-4253-b83c-b82218156493')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([Record(id=276760000, payload={'text': ' Welcome to the course on Cloud Computing. Today we will have our fast lecture. So, as you might have seen the broad overview of the course. So, in this particular series of lectures, we will try to give an overall picture of what Cloud Computing is and what are its major components and what are the recent trends and at the end maybe what are the different type of research opportunities or these trends of future trends in the Cloud Computing. So, before going to the details of Cloud Computing, we will try t', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760001, payload={'text': 'o have a quick overview of course, and the basic paradigm of computing. Now, if you look at that as defined by ACM computing, curricula in 2005 as the defined computing, it is a general way we can define computing to mean as a mean to solve any goal oriented activity. So, that means, it can be it can include starting from hardware software system for a wide range of purposes and also making computing systems intelligent using communications, finding gathering information from relevant to any particular purp', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760002, payload={'text': 'ose and so on. So, if you look at it has anything where some sort of a computing is needed, it falls under the computing paradigm. So, this gives us a broad spectrum of thing not only in terms of resources, also in terms of the terms or category or level of people who can who are going to use it. So, starting from a high end researcher or a professional to a student to event to a housewife or a citizen in general, look want to use it for its benefit or something which serves particular purpose. Before going', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760003, payload={'text': ' to other overview of this computing, I will let us try to reiterate the type of course, or type of things we will like to cover. So, initial lectures we will have a more things most likely today and maybe something on the next day that introduction to cloud computing, which has gives you overview what that NIST model says, what are the typical properties characteristics, advantage and disadvantages of cloud computing or role of open standard. So, how whether there is a standardization need or thing, then w', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760004, payload={'text': 'e will look at more as a cloud computing architecture. Like what is the typical computing cloud computing stack moving towards a service oriented architecture. So, what sort of service models are available in cloud like typically infrastructure as a service, platform as a service or software as a service or anything as a service. Later we will see that anything as a service whether we can realize, what are the different deployment models in case of a cloud, how when I want to deploy whether it is in a what ', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760005, payload={'text': 'will be the different deployment models of a cloud. Then one of the another major aspect of cloud is the service management. Like as we whenever we try to purchase any service or whenever I want to leverage any service, there is a need of service management like from the say consumer end, I would like to have what is the guarantee of minimal services from the provider end the cloud provider or cloud service provider CSP want to see that maybe the profit or maybe that how this guarantee what are the resource', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760006, payload={'text': ' requirement at the back end to serve so much computer. So, from the if you look at the provider consumer for any type of services not only cloud services any type of services in our day to day life we require some sort of a agreement between the service provider and the consumer. What in what we say something called service level agreement like I want to say that my availability will be 100 percent or near 100 percent based on my thing like I say when a exam is going on I want to have redundant services so', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760007, payload={'text': ' that the availability of the resources is 100 percent or very near 200 percent. Whereas, when my practice session is going on the requirement of availability may come down to 90 percent. Now, based on the availability the resource pooling or resource management will be done by the at the provider end and the provider will charge based on the type of type of resources type of availability etcetera. Then there are issues of downtime what will be there are issues of quality of services, there are several othe', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760008, payload={'text': 'r issues that we will try to discuss under the paradigm of service level agreements and other things. There is another another important person another important aspects is cloud dynamics or economy of using cloud computing. It may not be whether it is always good that if I use cloud it will be beneficial whether it is true like it is as as we see like suppose if you want to commute to 20 kilometer per day for your office or work then it may be economical to purchase a car. But if you are commuting say even', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None), Record(id=276760009, payload={'text': ' 50 kilometer or 100 kilometer once in a month it may not be economical then purchasing a car right it may be more economical than hiring a car right. Similarly, when I should hire when I should purchase whether there is a relationship whether there is economic model behind it or what if at all how to how do I from my say organization point of view maybe from a particular say event point of view whether I can see that whether purchasing or hiring a resources or is economical or what is the what is the econo', 'lecture_id': '1e239ed3-109f-496d-b5de-f77e96d353a0', 'course_id': '83c94b40-9dc0-4253-b83c-b82218156493'}, vector=None, shard_key=None, order_value=None)], 276760010)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Basic preprocessing: strip extra spaces.\"\"\"\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(text: str) -> list:\n",
    "    \"\"\"Split the lesson material into sentences using NLTK.\"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(sentences: list):\n",
    "    \"\"\"\n",
    "    Compute the TF-IDF matrix for the list of sentences.\n",
    "    Using ngram_range=(1, 2) captures both unigrams and bigrams.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    return tfidf_matrix, feature_names, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_from_sentence(sentence: str, keyword: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace the first occurrence of the keyword in the sentence with a blank.\n",
    "    This creates the question stem.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(re.escape(keyword), re.IGNORECASE)\n",
    "    question_sentence = pattern.sub(\"______\", sentence, count=1)\n",
    "    return question_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcqs(text: str, num_questions: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Generates MCQs by:\n",
    "    1. Preprocessing and splitting the document into sentences.\n",
    "    2. Computing TF-IDF (with n-grams) to extract keywords.\n",
    "    3. For each sentence, selecting the highest weighted word as the keyword,\n",
    "       replacing it with a blank, and generating a question.\n",
    "    4. Picking distractors from the overall top keywords.\n",
    "    \"\"\"\n",
    "    text = preprocess_text(text)\n",
    "    sentences = extract_sentences(text)\n",
    "    \n",
    "    # Compute TF-IDF for sentences\n",
    "    tfidf_matrix, feature_names, _ = compute_tfidf(sentences)\n",
    "    \n",
    "    # For distractor pool: Sum TF-IDF scores over the whole document\n",
    "    tfidf_sum = np.squeeze(np.asarray(tfidf_matrix.sum(axis=0)))\n",
    "    keywords_scores = list(zip(feature_names, tfidf_sum))\n",
    "    # Sort keywords by overall importance\n",
    "    keywords_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    # Select top keywords as the candidate pool\n",
    "    top_keywords = [kw for kw, score in keywords_scores[:10]]\n",
    "    \n",
    "    mcqs = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        row = tfidf_matrix[i].toarray().flatten()\n",
    "        if row.max() == 0:\n",
    "            continue  # Skip if the sentence has no useful keywords.\n",
    "        max_index = row.argmax()\n",
    "        correct_keyword = feature_names[max_index]\n",
    "        # Ensure the keyword appears in the sentence\n",
    "        if correct_keyword.lower() not in sentence.lower():\n",
    "            continue\n",
    "        \n",
    "        # Create the question by replacing the keyword with a blank.\n",
    "        question_text = generate_question_from_sentence(sentence, correct_keyword)\n",
    "        correct_answer = correct_keyword\n",
    "        \n",
    "        # Generate distractors: choose three other keywords from the pool\n",
    "        distractor_pool = [kw for kw in top_keywords if kw.lower() != correct_keyword.lower()]\n",
    "        if len(distractor_pool) < 3:\n",
    "            continue  # Skip if not enough distractors.\n",
    "        distractors = random.sample(distractor_pool, 3)\n",
    "        \n",
    "        # Combine correct answer with distractors and shuffle options.\n",
    "        options = [correct_answer] + distractors\n",
    "        random.shuffle(options)\n",
    "        option_labels = ['A', 'B', 'C', 'D']\n",
    "        options_dict = {label: opt for label, opt in zip(option_labels, options)}\n",
    "        correct_label = [label for label, opt in options_dict.items() if opt == correct_answer][0]\n",
    "        \n",
    "        mcq = {\n",
    "            \"question\": question_text,\n",
    "            \"options\": options_dict,\n",
    "            \"correct_answer\": correct_label,\n",
    "            \"explanation\": f\"The blank was filled by the keyword '{correct_answer}', extracted using TF-IDF.\"\n",
    "        }\n",
    "        mcqs.append(mcq)\n",
    "        if len(mcqs) >= num_questions:\n",
    "            break\n",
    "\n",
    "    return mcqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, _ = client.scroll(collection_name=\"course_83c94b40-9dc0-4253-b83c-b82218156493\", limit=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesson_text = \" \".join([record.payload.get(\"text\", \"\") for record in records])\n",
    "if not lesson_text.strip():\n",
    "    lesson_text = \"No lesson text found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated MCQs:\n",
      "[{\"question\": \"Today we will have our ______ lecture.\", \"options\": {\"A\": \"service\", \"B\": \"cloud computing\", \"C\": \"fast\", \"D\": \"terms\"}, \"correct_answer\": \"C\", \"explanation\": \"The blank was filled by the keyword 'fast', extracted using TF-IDF.\"}, {\"question\": \"So, as you might have seen the ______ of the course.\", \"options\": {\"A\": \"broad overview\", \"B\": \"computing\", \"C\": \"overview\", \"D\": \"broad\"}, \"correct_answer\": \"A\", \"explanation\": \"The blank was filled by the keyword 'broad overview', extracted using TF-IDF.\"}, {\"question\": \"So, in this particular series of lectures, we will try to give an overall picture of what Cloud Computing is and what are its major components and what are the recent ______ and at the end maybe what are the different type of research opportunities or these trends of future trends in the Cloud Computing.\", \"options\": {\"A\": \"trends\", \"B\": \"computing\", \"C\": \"course\", \"D\": \"broad\"}, \"correct_answer\": \"A\", \"explanation\": \"The blank was filled by the keyword 'trends', extracted using TF-IDF.\"}]\n"
     ]
    }
   ],
   "source": [
    "# Generate MCQs from the lesson text.\n",
    "generated_mcqs = generate_mcqs(lesson_text, num_questions=3)\n",
    "print(\"Generated MCQs:\")\n",
    "print(json.dumps(generated_mcqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"options\": {\n",
      "      \"A\": \"service\",\n",
      "      \"B\": \"cloud computing\",\n",
      "      \"C\": \"fast\",\n",
      "      \"D\": \"terms\"\n",
      "    },\n",
      "    \"question\": \"Today we will have our ______ lecture.\",\n",
      "    \"explanation\": \"The blank was filled by the keyword 'fast', extracted using TF-IDF.\",\n",
      "    \"correct_answer\": \"(C)\"\n",
      "  },\n",
      "  {\n",
      "    \"options\": {\n",
      "      \"A\": \"broad overview\",\n",
      "      \"B\": \"computing\",\n",
      "      \"C\": \"overview\",\n",
      "      \"D\": \"broad\"\n",
      "    },\n",
      "    \"question\": \"So, as you might have seen the ______ of the course.\",\n",
      "    \"explanation\": \"The blank was filled by the keyword 'broad overview', extracted using TF-IDF.\",\n",
      "    \"correct_answer\": \"(A)\"\n",
      "  },\n",
      "  {\n",
      "    \"options\": {\n",
      "      \"A\": \"trends\",\n",
      "      \"B\": \"computing\",\n",
      "      \"C\": \"course\",\n",
      "      \"D\": \"broad\"\n",
      "    },\n",
      "    \"question\": \"So, in this particular series of lectures, we will try to give an overall picture of what Cloud Computing is and what are its major components and what are the recent ______ and at the end maybe what are the different type of research opportunities or these trends of future trends in the Cloud Computing.\",\n",
      "    \"explanation\": \"The blank was filled by the keyword 'trends', extracted using TF-IDF.\",\n",
      "    \"correct_answer\": \"(A)\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "def transform_quiz_format(mcqs):\n",
    "    formatted = []\n",
    "    for mcq in mcqs:\n",
    "        # Wrap the correct answer in parentheses\n",
    "        transformed = {\n",
    "            \"options\": mcq[\"options\"],\n",
    "            \"question\": mcq[\"question\"],\n",
    "            \"explanation\": mcq[\"explanation\"],\n",
    "            \"correct_answer\": f\"({mcq['correct_answer']})\"\n",
    "        }\n",
    "        formatted.append(transformed)\n",
    "    return formatted\n",
    "\n",
    "# Assuming generated_mcqs is the output from your quiz generation function:\n",
    "formatted_quiz = transform_quiz_format(generated_mcqs)\n",
    "print(json.dumps(formatted_quiz, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elevateded",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
